/home/ai1/anaconda3/envs/thai/bin/python /home/ai1/ThaiLQ/Locality-iN-Locality/train_LiL.py 
PyTorch 2.6.0+cu124
Torchvision 0.21.0+cu124
Torchattacks 3.5.1
Numpy 2.2.3
------------------------------------------------
Epoch [1/100], Iter [200/784], Loss: 2.840451
Epoch [1/100], Iter [400/784], Loss: 2.001090
Epoch [1/100], Iter [600/784], Loss: 1.940944
--------------------------------------------------------------------
Epoch [1/100], Test Loss: 1.395670, Overall Accuracy: 55.09%
Highest accuracy: 55.09% achieved at epoch 1
--------------------------------------------------------------------
Epoch [2/100], Iter [200/784], Loss: 0.309447
Epoch [2/100], Iter [400/784], Loss: 0.054298
Epoch [2/100], Iter [600/784], Loss: 0.075152
--------------------------------------------------------------------
Epoch [2/100], Test Loss: 0.158289, Overall Accuracy: 96.32%
Highest accuracy: 96.32% achieved at epoch 2
--------------------------------------------------------------------
Epoch [3/100], Iter [200/784], Loss: 0.053834
Epoch [3/100], Iter [400/784], Loss: 0.012867
Epoch [3/100], Iter [600/784], Loss: 0.014164
--------------------------------------------------------------------
Epoch [3/100], Test Loss: 0.145360, Overall Accuracy: 96.33%
Highest accuracy: 96.33% achieved at epoch 3
--------------------------------------------------------------------
Epoch [4/100], Iter [200/784], Loss: 0.002619
Epoch [4/100], Iter [400/784], Loss: 0.004561
Epoch [4/100], Iter [600/784], Loss: 0.002328
--------------------------------------------------------------------
Epoch [4/100], Test Loss: 0.099737, Overall Accuracy: 97.50%
Highest accuracy: 97.50% achieved at epoch 4
--------------------------------------------------------------------
Epoch [5/100], Iter [200/784], Loss: 0.001087
Epoch [5/100], Iter [400/784], Loss: 0.001369
Epoch [5/100], Iter [600/784], Loss: 0.002082
--------------------------------------------------------------------
Epoch [5/100], Test Loss: 0.092590, Overall Accuracy: 97.58%
Highest accuracy: 97.58% achieved at epoch 5
--------------------------------------------------------------------
Epoch [6/100], Iter [200/784], Loss: 0.002234
Epoch [6/100], Iter [400/784], Loss: 0.001211
Epoch [6/100], Iter [600/784], Loss: 0.001005
--------------------------------------------------------------------
Epoch [6/100], Test Loss: 0.085045, Overall Accuracy: 97.81%
Highest accuracy: 97.81% achieved at epoch 6
--------------------------------------------------------------------
Epoch [7/100], Iter [200/784], Loss: 0.000583
Epoch [7/100], Iter [400/784], Loss: 0.000705
Epoch [7/100], Iter [600/784], Loss: 0.000672
--------------------------------------------------------------------
Epoch [7/100], Test Loss: 0.084252, Overall Accuracy: 97.81%
Highest accuracy: 97.81% achieved at epoch 6
--------------------------------------------------------------------
Epoch [8/100], Iter [200/784], Loss: 0.001083
Epoch [8/100], Iter [400/784], Loss: 0.000824
Epoch [8/100], Iter [600/784], Loss: 0.000717
--------------------------------------------------------------------
Epoch [8/100], Test Loss: 0.085142, Overall Accuracy: 97.77%
Highest accuracy: 97.81% achieved at epoch 6
--------------------------------------------------------------------
Epoch [9/100], Iter [200/784], Loss: 0.000823
Epoch [9/100], Iter [400/784], Loss: 0.000962
Epoch [9/100], Iter [600/784], Loss: 0.000969
--------------------------------------------------------------------
Epoch [9/100], Test Loss: 0.082245, Overall Accuracy: 97.97%
Highest accuracy: 97.97% achieved at epoch 9
--------------------------------------------------------------------
Epoch [10/100], Iter [200/784], Loss: 0.000439
Epoch [10/100], Iter [400/784], Loss: 0.000494
Epoch [10/100], Iter [600/784], Loss: 0.000586
--------------------------------------------------------------------
Epoch [10/100], Test Loss: 0.081075, Overall Accuracy: 97.94%
Highest accuracy: 97.97% achieved at epoch 9
--------------------------------------------------------------------
Epoch [11/100], Iter [200/784], Loss: 0.000597
Epoch [11/100], Iter [400/784], Loss: 0.000317
Epoch [11/100], Iter [600/784], Loss: 0.000416
--------------------------------------------------------------------
Epoch [11/100], Test Loss: 0.082837, Overall Accuracy: 97.91%
Highest accuracy: 97.97% achieved at epoch 9
--------------------------------------------------------------------
Epoch [12/100], Iter [200/784], Loss: 0.000618
Epoch [12/100], Iter [400/784], Loss: 0.000385
Epoch [12/100], Iter [600/784], Loss: 0.000411
--------------------------------------------------------------------
Epoch [12/100], Test Loss: 0.081024, Overall Accuracy: 97.93%
Highest accuracy: 97.97% achieved at epoch 9
--------------------------------------------------------------------
Epoch [13/100], Iter [200/784], Loss: 0.000310
Epoch [13/100], Iter [400/784], Loss: 0.000287
Epoch [13/100], Iter [600/784], Loss: 0.000369
--------------------------------------------------------------------
Epoch [13/100], Test Loss: 0.080804, Overall Accuracy: 98.03%
Highest accuracy: 98.03% achieved at epoch 13
--------------------------------------------------------------------
Epoch [14/100], Iter [200/784], Loss: 0.000269
Epoch [14/100], Iter [400/784], Loss: 0.000328
Epoch [14/100], Iter [600/784], Loss: 0.000347
--------------------------------------------------------------------
Epoch [14/100], Test Loss: 0.080886, Overall Accuracy: 98.09%
Highest accuracy: 98.09% achieved at epoch 14
--------------------------------------------------------------------
Epoch [15/100], Iter [200/784], Loss: 0.000428
Epoch [15/100], Iter [400/784], Loss: 0.000420
Epoch [15/100], Iter [600/784], Loss: 0.000384
--------------------------------------------------------------------
Epoch [15/100], Test Loss: 0.081897, Overall Accuracy: 97.94%
Highest accuracy: 98.09% achieved at epoch 14
--------------------------------------------------------------------
Epoch [16/100], Iter [200/784], Loss: 0.000390
Epoch [16/100], Iter [400/784], Loss: 0.000271
Epoch [16/100], Iter [600/784], Loss: 0.000272
--------------------------------------------------------------------
Epoch [16/100], Test Loss: 0.082482, Overall Accuracy: 98.03%
Highest accuracy: 98.09% achieved at epoch 14
--------------------------------------------------------------------
Epoch [17/100], Iter [200/784], Loss: 0.000375
Epoch [17/100], Iter [400/784], Loss: 0.000247
Epoch [17/100], Iter [600/784], Loss: 0.000258
--------------------------------------------------------------------
Epoch [17/100], Test Loss: 0.081176, Overall Accuracy: 98.07%
Highest accuracy: 98.09% achieved at epoch 14
--------------------------------------------------------------------
Epoch [18/100], Iter [200/784], Loss: 0.000339
Epoch [18/100], Iter [400/784], Loss: 0.000231
Epoch [18/100], Iter [600/784], Loss: 0.000223
--------------------------------------------------------------------
Epoch [18/100], Test Loss: 0.080786, Overall Accuracy: 98.05%
Highest accuracy: 98.09% achieved at epoch 14
--------------------------------------------------------------------
Epoch [19/100], Iter [200/784], Loss: 0.000242
Epoch [19/100], Iter [400/784], Loss: 0.000273
Epoch [19/100], Iter [600/784], Loss: 0.000281
--------------------------------------------------------------------
Epoch [19/100], Test Loss: 0.080106, Overall Accuracy: 98.08%
Highest accuracy: 98.09% achieved at epoch 14
--------------------------------------------------------------------
Epoch [20/100], Iter [200/784], Loss: 0.000180
Epoch [20/100], Iter [400/784], Loss: 0.000138
Epoch [20/100], Iter [600/784], Loss: 0.000205
--------------------------------------------------------------------
Epoch [20/100], Test Loss: 0.077643, Overall Accuracy: 98.11%
Highest accuracy: 98.11% achieved at epoch 20
--------------------------------------------------------------------
Epoch [21/100], Iter [200/784], Loss: 0.000249
Epoch [21/100], Iter [400/784], Loss: 0.000237
Epoch [21/100], Iter [600/784], Loss: 0.000460
--------------------------------------------------------------------
Epoch [21/100], Test Loss: 0.078174, Overall Accuracy: 98.08%
Highest accuracy: 98.11% achieved at epoch 20
--------------------------------------------------------------------
Epoch [22/100], Iter [200/784], Loss: 0.000216
Epoch [22/100], Iter [400/784], Loss: 0.000145
Epoch [22/100], Iter [600/784], Loss: 0.000201
--------------------------------------------------------------------
Epoch [22/100], Test Loss: 0.080988, Overall Accuracy: 98.06%
Highest accuracy: 98.11% achieved at epoch 20
--------------------------------------------------------------------
Epoch [23/100], Iter [200/784], Loss: 0.000200
Epoch [23/100], Iter [400/784], Loss: 0.000153
Epoch [23/100], Iter [600/784], Loss: 0.000164
--------------------------------------------------------------------
Epoch [23/100], Test Loss: 0.077451, Overall Accuracy: 98.15%
Highest accuracy: 98.15% achieved at epoch 23
--------------------------------------------------------------------
Epoch [24/100], Iter [200/784], Loss: 0.000129
Epoch [24/100], Iter [400/784], Loss: 0.000135
Epoch [24/100], Iter [600/784], Loss: 0.000135
--------------------------------------------------------------------
Epoch [24/100], Test Loss: 0.077089, Overall Accuracy: 98.17%
Highest accuracy: 98.17% achieved at epoch 24
--------------------------------------------------------------------
Epoch [25/100], Iter [200/784], Loss: 0.000150
Epoch [25/100], Iter [400/784], Loss: 0.000153
Epoch [25/100], Iter [600/784], Loss: 0.000168
--------------------------------------------------------------------
Epoch [25/100], Test Loss: 0.078981, Overall Accuracy: 98.08%
Highest accuracy: 98.17% achieved at epoch 24
--------------------------------------------------------------------
Epoch [26/100], Iter [200/784], Loss: 0.000175
Epoch [26/100], Iter [400/784], Loss: 0.000160
Epoch [26/100], Iter [600/784], Loss: 0.000145
--------------------------------------------------------------------
Epoch [26/100], Test Loss: 0.077987, Overall Accuracy: 98.22%
Highest accuracy: 98.22% achieved at epoch 26
--------------------------------------------------------------------
Epoch [27/100], Iter [200/784], Loss: 0.000172
Epoch [27/100], Iter [400/784], Loss: 0.000305
Epoch [27/100], Iter [600/784], Loss: 0.000192
--------------------------------------------------------------------
Epoch [27/100], Test Loss: 0.077265, Overall Accuracy: 98.19%
Highest accuracy: 98.22% achieved at epoch 26
--------------------------------------------------------------------
Epoch [28/100], Iter [200/784], Loss: 0.000153
Epoch [28/100], Iter [400/784], Loss: 0.000147
Epoch [28/100], Iter [600/784], Loss: 0.000175
--------------------------------------------------------------------
Epoch [28/100], Test Loss: 0.078730, Overall Accuracy: 98.12%
Highest accuracy: 98.22% achieved at epoch 26
--------------------------------------------------------------------
Epoch [29/100], Iter [200/784], Loss: 0.000214
Epoch [29/100], Iter [400/784], Loss: 0.000163
Epoch [29/100], Iter [600/784], Loss: 0.000179
--------------------------------------------------------------------
Epoch [29/100], Test Loss: 0.078017, Overall Accuracy: 98.12%
Highest accuracy: 98.22% achieved at epoch 26
--------------------------------------------------------------------
Epoch [30/100], Iter [200/784], Loss: 0.000110
Epoch [30/100], Iter [400/784], Loss: 0.000222
Epoch [30/100], Iter [600/784], Loss: 0.000224
--------------------------------------------------------------------
Epoch [30/100], Test Loss: 0.076333, Overall Accuracy: 98.21%
Highest accuracy: 98.22% achieved at epoch 26
--------------------------------------------------------------------
Epoch [31/100], Iter [200/784], Loss: 0.000218
Epoch [31/100], Iter [400/784], Loss: 0.000127
Epoch [31/100], Iter [600/784], Loss: 0.000211
--------------------------------------------------------------------
Epoch [31/100], Test Loss: 0.079137, Overall Accuracy: 98.11%
Highest accuracy: 98.22% achieved at epoch 26
--------------------------------------------------------------------
Epoch [32/100], Iter [200/784], Loss: 0.000134
Epoch [32/100], Iter [400/784], Loss: 0.000111
Epoch [32/100], Iter [600/784], Loss: 0.000178
--------------------------------------------------------------------
Epoch [32/100], Test Loss: 0.076672, Overall Accuracy: 98.19%
Highest accuracy: 98.22% achieved at epoch 26
--------------------------------------------------------------------
Epoch [33/100], Iter [200/784], Loss: 0.000198
Epoch [33/100], Iter [400/784], Loss: 0.000164
Epoch [33/100], Iter [600/784], Loss: 0.000146
--------------------------------------------------------------------
Epoch [33/100], Test Loss: 0.077092, Overall Accuracy: 98.20%
Highest accuracy: 98.22% achieved at epoch 26
--------------------------------------------------------------------
Epoch [34/100], Iter [200/784], Loss: 0.000185
Epoch [34/100], Iter [400/784], Loss: 0.000153
Epoch [34/100], Iter [600/784], Loss: 0.000208
--------------------------------------------------------------------
Epoch [34/100], Test Loss: 0.078778, Overall Accuracy: 98.16%
Highest accuracy: 98.22% achieved at epoch 26
--------------------------------------------------------------------
Epoch [35/100], Iter [200/784], Loss: 0.000117
Epoch [35/100], Iter [400/784], Loss: 0.000105
Epoch [35/100], Iter [600/784], Loss: 0.000121
--------------------------------------------------------------------
Epoch [35/100], Test Loss: 0.077843, Overall Accuracy: 98.17%
Highest accuracy: 98.22% achieved at epoch 26
--------------------------------------------------------------------
Epoch [36/100], Iter [200/784], Loss: 0.000171
Epoch [36/100], Iter [400/784], Loss: 0.000135
Epoch [36/100], Iter [600/784], Loss: 0.000131
--------------------------------------------------------------------
Epoch [36/100], Test Loss: 0.077925, Overall Accuracy: 98.16%
Highest accuracy: 98.22% achieved at epoch 26
--------------------------------------------------------------------
Epoch [37/100], Iter [200/784], Loss: 0.000087
Epoch [37/100], Iter [400/784], Loss: 0.000105
Epoch [37/100], Iter [600/784], Loss: 0.000077
--------------------------------------------------------------------
Epoch [37/100], Test Loss: 0.077244, Overall Accuracy: 98.20%
Highest accuracy: 98.22% achieved at epoch 26
--------------------------------------------------------------------
Epoch [38/100], Iter [200/784], Loss: 0.000164
Epoch [38/100], Iter [400/784], Loss: 0.000185
Epoch [38/100], Iter [600/784], Loss: 0.000132
--------------------------------------------------------------------
Epoch [38/100], Test Loss: 0.077927, Overall Accuracy: 98.24%
Highest accuracy: 98.24% achieved at epoch 38
--------------------------------------------------------------------
Epoch [39/100], Iter [200/784], Loss: 0.000092
Epoch [39/100], Iter [400/784], Loss: 0.000117
Epoch [39/100], Iter [600/784], Loss: 0.000080
--------------------------------------------------------------------
Epoch [39/100], Test Loss: 0.076930, Overall Accuracy: 98.19%
Highest accuracy: 98.24% achieved at epoch 38
--------------------------------------------------------------------
Epoch [40/100], Iter [200/784], Loss: 0.000087
Epoch [40/100], Iter [400/784], Loss: 0.000136
Epoch [40/100], Iter [600/784], Loss: 0.000094
--------------------------------------------------------------------
Epoch [40/100], Test Loss: 0.078104, Overall Accuracy: 98.16%
Highest accuracy: 98.24% achieved at epoch 38
--------------------------------------------------------------------
Epoch [41/100], Iter [200/784], Loss: 0.000098
Epoch [41/100], Iter [400/784], Loss: 0.000080
Epoch [41/100], Iter [600/784], Loss: 0.000083
--------------------------------------------------------------------
Epoch [41/100], Test Loss: 0.076603, Overall Accuracy: 98.23%
Highest accuracy: 98.24% achieved at epoch 38
--------------------------------------------------------------------
Epoch [42/100], Iter [200/784], Loss: 0.000102
Epoch [42/100], Iter [400/784], Loss: 0.000098
Epoch [42/100], Iter [600/784], Loss: 0.000149
--------------------------------------------------------------------
Epoch [42/100], Test Loss: 0.080463, Overall Accuracy: 98.12%
Highest accuracy: 98.24% achieved at epoch 38
--------------------------------------------------------------------
Epoch [43/100], Iter [200/784], Loss: 0.000075
Epoch [43/100], Iter [400/784], Loss: 0.000101
Epoch [43/100], Iter [600/784], Loss: 0.000085
--------------------------------------------------------------------
Epoch [43/100], Test Loss: 0.077399, Overall Accuracy: 98.20%
Highest accuracy: 98.24% achieved at epoch 38
--------------------------------------------------------------------
Epoch [44/100], Iter [200/784], Loss: 0.000133
Epoch [44/100], Iter [400/784], Loss: 0.000095
Epoch [44/100], Iter [600/784], Loss: 0.000109
--------------------------------------------------------------------
Epoch [44/100], Test Loss: 0.076884, Overall Accuracy: 98.23%
Highest accuracy: 98.24% achieved at epoch 38
--------------------------------------------------------------------
Epoch [45/100], Iter [200/784], Loss: 0.000094
Epoch [45/100], Iter [400/784], Loss: 0.000087
Epoch [45/100], Iter [600/784], Loss: 0.000114
--------------------------------------------------------------------
Epoch [45/100], Test Loss: 0.076368, Overall Accuracy: 98.25%
Highest accuracy: 98.25% achieved at epoch 45
--------------------------------------------------------------------
Epoch [46/100], Iter [200/784], Loss: 0.000121
Epoch [46/100], Iter [400/784], Loss: 0.000111
Epoch [46/100], Iter [600/784], Loss: 0.000124
--------------------------------------------------------------------
Epoch [46/100], Test Loss: 0.075479, Overall Accuracy: 98.27%
Highest accuracy: 98.27% achieved at epoch 46
--------------------------------------------------------------------
Epoch [47/100], Iter [200/784], Loss: 0.000087
Epoch [47/100], Iter [400/784], Loss: 0.000114
Epoch [47/100], Iter [600/784], Loss: 0.000114
--------------------------------------------------------------------
Epoch [47/100], Test Loss: 0.077479, Overall Accuracy: 98.19%
Highest accuracy: 98.27% achieved at epoch 46
--------------------------------------------------------------------
Epoch [48/100], Iter [200/784], Loss: 0.000111
Epoch [48/100], Iter [400/784], Loss: 0.000057
Epoch [48/100], Iter [600/784], Loss: 0.000092
--------------------------------------------------------------------
Epoch [48/100], Test Loss: 0.076783, Overall Accuracy: 98.25%
Highest accuracy: 98.27% achieved at epoch 46
--------------------------------------------------------------------
Epoch [49/100], Iter [200/784], Loss: 0.000086
Epoch [49/100], Iter [400/784], Loss: 0.000106
Epoch [49/100], Iter [600/784], Loss: 0.000073
--------------------------------------------------------------------
Epoch [49/100], Test Loss: 0.078796, Overall Accuracy: 98.17%
Highest accuracy: 98.27% achieved at epoch 46
--------------------------------------------------------------------
Epoch [50/100], Iter [200/784], Loss: 0.000129
Epoch [50/100], Iter [400/784], Loss: 0.000059
Epoch [50/100], Iter [600/784], Loss: 0.000060
--------------------------------------------------------------------
Epoch [50/100], Test Loss: 0.076000, Overall Accuracy: 98.30%
Highest accuracy: 98.30% achieved at epoch 50
--------------------------------------------------------------------
Epoch [51/100], Iter [200/784], Loss: 0.000071
Epoch [51/100], Iter [400/784], Loss: 0.000065
Epoch [51/100], Iter [600/784], Loss: 0.000095
--------------------------------------------------------------------
Epoch [51/100], Test Loss: 0.076352, Overall Accuracy: 98.24%
Highest accuracy: 98.30% achieved at epoch 50
--------------------------------------------------------------------
Epoch [52/100], Iter [200/784], Loss: 0.000077
Epoch [52/100], Iter [400/784], Loss: 0.000068
Epoch [52/100], Iter [600/784], Loss: 0.000062
--------------------------------------------------------------------
Epoch [52/100], Test Loss: 0.077482, Overall Accuracy: 98.23%
Highest accuracy: 98.30% achieved at epoch 50
--------------------------------------------------------------------
Epoch [53/100], Iter [200/784], Loss: 0.000094
Epoch [53/100], Iter [400/784], Loss: 0.000091
Epoch [53/100], Iter [600/784], Loss: 0.000083
--------------------------------------------------------------------
Epoch [53/100], Test Loss: 0.075985, Overall Accuracy: 98.28%
Highest accuracy: 98.30% achieved at epoch 50
--------------------------------------------------------------------
Epoch [54/100], Iter [200/784], Loss: 0.000071
Epoch [54/100], Iter [400/784], Loss: 0.000096
Epoch [54/100], Iter [600/784], Loss: 0.000063
--------------------------------------------------------------------
Epoch [54/100], Test Loss: 0.075639, Overall Accuracy: 98.31%
Highest accuracy: 98.31% achieved at epoch 54
--------------------------------------------------------------------
Epoch [55/100], Iter [200/784], Loss: 0.000085
Epoch [55/100], Iter [400/784], Loss: 0.000095
Epoch [55/100], Iter [600/784], Loss: 0.000113
--------------------------------------------------------------------
Epoch [55/100], Test Loss: 0.075926, Overall Accuracy: 98.28%
Highest accuracy: 98.31% achieved at epoch 54
--------------------------------------------------------------------
Epoch [56/100], Iter [200/784], Loss: 0.000086
Epoch [56/100], Iter [400/784], Loss: 0.000072
Epoch [56/100], Iter [600/784], Loss: 0.000061
--------------------------------------------------------------------
Epoch [56/100], Test Loss: 0.076299, Overall Accuracy: 98.26%
Highest accuracy: 98.31% achieved at epoch 54
--------------------------------------------------------------------
Epoch [57/100], Iter [200/784], Loss: 0.000062
Epoch [57/100], Iter [400/784], Loss: 0.000089
Epoch [57/100], Iter [600/784], Loss: 0.000099
--------------------------------------------------------------------
Epoch [57/100], Test Loss: 0.075693, Overall Accuracy: 98.26%
Highest accuracy: 98.31% achieved at epoch 54
--------------------------------------------------------------------
Epoch [58/100], Iter [200/784], Loss: 0.000070
Epoch [58/100], Iter [400/784], Loss: 0.000080
Epoch [58/100], Iter [600/784], Loss: 0.000079
--------------------------------------------------------------------
Epoch [58/100], Test Loss: 0.076423, Overall Accuracy: 98.31%
Highest accuracy: 98.31% achieved at epoch 54
--------------------------------------------------------------------
Epoch [59/100], Iter [200/784], Loss: 0.000050
Epoch [59/100], Iter [400/784], Loss: 0.000066
Epoch [59/100], Iter [600/784], Loss: 0.000080
--------------------------------------------------------------------
Epoch [59/100], Test Loss: 0.076554, Overall Accuracy: 98.33%
Highest accuracy: 98.33% achieved at epoch 59
--------------------------------------------------------------------
Epoch [60/100], Iter [200/784], Loss: 0.000095
Epoch [60/100], Iter [400/784], Loss: 0.000064
Epoch [60/100], Iter [600/784], Loss: 0.000102
--------------------------------------------------------------------
Epoch [60/100], Test Loss: 0.075500, Overall Accuracy: 98.33%
Highest accuracy: 98.33% achieved at epoch 59
--------------------------------------------------------------------
Epoch [61/100], Iter [200/784], Loss: 0.000078
Epoch [61/100], Iter [400/784], Loss: 0.000079
Epoch [61/100], Iter [600/784], Loss: 0.000130
--------------------------------------------------------------------
Epoch [61/100], Test Loss: 0.077054, Overall Accuracy: 98.29%
Highest accuracy: 98.33% achieved at epoch 59
--------------------------------------------------------------------
Epoch [62/100], Iter [200/784], Loss: 0.000065
Epoch [62/100], Iter [400/784], Loss: 0.000045
Epoch [62/100], Iter [600/784], Loss: 0.000058
--------------------------------------------------------------------
Epoch [62/100], Test Loss: 0.076918, Overall Accuracy: 98.28%
Highest accuracy: 98.33% achieved at epoch 59
--------------------------------------------------------------------
Epoch [63/100], Iter [200/784], Loss: 0.000066
Epoch [63/100], Iter [400/784], Loss: 0.000056
Epoch [63/100], Iter [600/784], Loss: 0.000078
--------------------------------------------------------------------
Epoch [63/100], Test Loss: 0.074257, Overall Accuracy: 98.33%
Highest accuracy: 98.33% achieved at epoch 59
--------------------------------------------------------------------
Epoch [64/100], Iter [200/784], Loss: 0.000079
Epoch [64/100], Iter [400/784], Loss: 0.000085
Epoch [64/100], Iter [600/784], Loss: 0.000069
--------------------------------------------------------------------
Epoch [64/100], Test Loss: 0.075503, Overall Accuracy: 98.25%
Highest accuracy: 98.33% achieved at epoch 59
--------------------------------------------------------------------
Epoch [65/100], Iter [200/784], Loss: 0.000073
Epoch [65/100], Iter [400/784], Loss: 0.000084
Epoch [65/100], Iter [600/784], Loss: 0.000065
--------------------------------------------------------------------
Epoch [65/100], Test Loss: 0.076858, Overall Accuracy: 98.27%
Highest accuracy: 98.33% achieved at epoch 59
--------------------------------------------------------------------
Epoch [66/100], Iter [200/784], Loss: 0.000048
Epoch [66/100], Iter [400/784], Loss: 0.000075
Epoch [66/100], Iter [600/784], Loss: 0.000052
--------------------------------------------------------------------
Epoch [66/100], Test Loss: 0.076344, Overall Accuracy: 98.32%
Highest accuracy: 98.33% achieved at epoch 59
--------------------------------------------------------------------
Epoch [67/100], Iter [200/784], Loss: 0.000056
Epoch [67/100], Iter [400/784], Loss: 0.000091
Epoch [67/100], Iter [600/784], Loss: 0.000071
--------------------------------------------------------------------
Epoch [67/100], Test Loss: 0.076068, Overall Accuracy: 98.27%
Highest accuracy: 98.33% achieved at epoch 59
--------------------------------------------------------------------
Epoch [68/100], Iter [200/784], Loss: 0.000075
Epoch [68/100], Iter [400/784], Loss: 0.000049
Epoch [68/100], Iter [600/784], Loss: 0.000053
--------------------------------------------------------------------
Epoch [68/100], Test Loss: 0.075220, Overall Accuracy: 98.32%
Highest accuracy: 98.33% achieved at epoch 59
--------------------------------------------------------------------
Epoch [69/100], Iter [200/784], Loss: 0.000086
Epoch [69/100], Iter [400/784], Loss: 0.000081
Epoch [69/100], Iter [600/784], Loss: 0.000056
--------------------------------------------------------------------
Epoch [69/100], Test Loss: 0.076992, Overall Accuracy: 98.23%
Highest accuracy: 98.33% achieved at epoch 59
--------------------------------------------------------------------
Epoch [70/100], Iter [200/784], Loss: 0.000057
Epoch [70/100], Iter [400/784], Loss: 0.000074
Epoch [70/100], Iter [600/784], Loss: 0.000050
--------------------------------------------------------------------
Epoch [70/100], Test Loss: 0.076333, Overall Accuracy: 98.27%
Highest accuracy: 98.33% achieved at epoch 59
--------------------------------------------------------------------
Epoch [71/100], Iter [200/784], Loss: 0.000067
Epoch [71/100], Iter [400/784], Loss: 0.000072
Epoch [71/100], Iter [600/784], Loss: 0.000062
--------------------------------------------------------------------
Epoch [71/100], Test Loss: 0.075265, Overall Accuracy: 98.35%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [72/100], Iter [200/784], Loss: 0.000079
Epoch [72/100], Iter [400/784], Loss: 0.000035
Epoch [72/100], Iter [600/784], Loss: 0.000056
--------------------------------------------------------------------
Epoch [72/100], Test Loss: 0.076413, Overall Accuracy: 98.29%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [73/100], Iter [200/784], Loss: 0.000059
Epoch [73/100], Iter [400/784], Loss: 0.000050
Epoch [73/100], Iter [600/784], Loss: 0.000046
--------------------------------------------------------------------
Epoch [73/100], Test Loss: 0.078661, Overall Accuracy: 98.20%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [74/100], Iter [200/784], Loss: 0.000064
Epoch [74/100], Iter [400/784], Loss: 0.000052
Epoch [74/100], Iter [600/784], Loss: 0.000064
--------------------------------------------------------------------
Epoch [74/100], Test Loss: 0.075165, Overall Accuracy: 98.34%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [75/100], Iter [200/784], Loss: 0.000047
Epoch [75/100], Iter [400/784], Loss: 0.000041
Epoch [75/100], Iter [600/784], Loss: 0.000043
--------------------------------------------------------------------
Epoch [75/100], Test Loss: 0.077846, Overall Accuracy: 98.25%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [76/100], Iter [200/784], Loss: 0.000055
Epoch [76/100], Iter [400/784], Loss: 0.000051
Epoch [76/100], Iter [600/784], Loss: 0.000047
--------------------------------------------------------------------
Epoch [76/100], Test Loss: 0.076322, Overall Accuracy: 98.31%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [77/100], Iter [200/784], Loss: 0.000055
Epoch [77/100], Iter [400/784], Loss: 0.000092
Epoch [77/100], Iter [600/784], Loss: 0.000059
--------------------------------------------------------------------
Epoch [77/100], Test Loss: 0.076220, Overall Accuracy: 98.27%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [78/100], Iter [200/784], Loss: 0.000068
Epoch [78/100], Iter [400/784], Loss: 0.000038
Epoch [78/100], Iter [600/784], Loss: 0.000056
--------------------------------------------------------------------
Epoch [78/100], Test Loss: 0.077184, Overall Accuracy: 98.27%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [79/100], Iter [200/784], Loss: 0.000043
Epoch [79/100], Iter [400/784], Loss: 0.000083
Epoch [79/100], Iter [600/784], Loss: 0.000074
--------------------------------------------------------------------
Epoch [79/100], Test Loss: 0.076113, Overall Accuracy: 98.25%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [80/100], Iter [200/784], Loss: 0.000041
Epoch [80/100], Iter [400/784], Loss: 0.000068
Epoch [80/100], Iter [600/784], Loss: 0.000055
--------------------------------------------------------------------
Epoch [80/100], Test Loss: 0.077643, Overall Accuracy: 98.28%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [81/100], Iter [200/784], Loss: 0.000034
Epoch [81/100], Iter [400/784], Loss: 0.000070
Epoch [81/100], Iter [600/784], Loss: 0.000055
--------------------------------------------------------------------
Epoch [81/100], Test Loss: 0.076282, Overall Accuracy: 98.32%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [82/100], Iter [200/784], Loss: 0.000037
Epoch [82/100], Iter [400/784], Loss: 0.000081
Epoch [82/100], Iter [600/784], Loss: 0.000046
--------------------------------------------------------------------
Epoch [82/100], Test Loss: 0.075450, Overall Accuracy: 98.33%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [83/100], Iter [200/784], Loss: 0.000055
Epoch [83/100], Iter [400/784], Loss: 0.000058
Epoch [83/100], Iter [600/784], Loss: 0.000061
--------------------------------------------------------------------
Epoch [83/100], Test Loss: 0.075840, Overall Accuracy: 98.32%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [84/100], Iter [200/784], Loss: 0.000057
Epoch [84/100], Iter [400/784], Loss: 0.000056
Epoch [84/100], Iter [600/784], Loss: 0.000042
--------------------------------------------------------------------
Epoch [84/100], Test Loss: 0.076686, Overall Accuracy: 98.35%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [85/100], Iter [200/784], Loss: 0.000074
Epoch [85/100], Iter [400/784], Loss: 0.000049
Epoch [85/100], Iter [600/784], Loss: 0.000078
--------------------------------------------------------------------
Epoch [85/100], Test Loss: 0.076253, Overall Accuracy: 98.32%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [86/100], Iter [200/784], Loss: 0.000092
Epoch [86/100], Iter [400/784], Loss: 0.000053
Epoch [86/100], Iter [600/784], Loss: 0.000036
--------------------------------------------------------------------
Epoch [86/100], Test Loss: 0.078647, Overall Accuracy: 98.27%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [87/100], Iter [200/784], Loss: 0.000059
Epoch [87/100], Iter [400/784], Loss: 0.000059
Epoch [87/100], Iter [600/784], Loss: 0.000046
--------------------------------------------------------------------
Epoch [87/100], Test Loss: 0.076841, Overall Accuracy: 98.31%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [88/100], Iter [200/784], Loss: 0.000062
Epoch [88/100], Iter [400/784], Loss: 0.000038
Epoch [88/100], Iter [600/784], Loss: 0.000065
--------------------------------------------------------------------
Epoch [88/100], Test Loss: 0.076864, Overall Accuracy: 98.27%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [89/100], Iter [200/784], Loss: 0.000030
Epoch [89/100], Iter [400/784], Loss: 0.000057
Epoch [89/100], Iter [600/784], Loss: 0.000059
--------------------------------------------------------------------
Epoch [89/100], Test Loss: 0.077152, Overall Accuracy: 98.31%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [90/100], Iter [200/784], Loss: 0.000042
Epoch [90/100], Iter [400/784], Loss: 0.000057
Epoch [90/100], Iter [600/784], Loss: 0.000040
--------------------------------------------------------------------
Epoch [90/100], Test Loss: 0.075383, Overall Accuracy: 98.31%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [91/100], Iter [200/784], Loss: 0.000049
Epoch [91/100], Iter [400/784], Loss: 0.000041
Epoch [91/100], Iter [600/784], Loss: 0.000053
--------------------------------------------------------------------
Epoch [91/100], Test Loss: 0.075481, Overall Accuracy: 98.34%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [92/100], Iter [200/784], Loss: 0.000060
Epoch [92/100], Iter [400/784], Loss: 0.000043
Epoch [92/100], Iter [600/784], Loss: 0.000062
--------------------------------------------------------------------
Epoch [92/100], Test Loss: 0.076799, Overall Accuracy: 98.29%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [93/100], Iter [200/784], Loss: 0.000045
Epoch [93/100], Iter [400/784], Loss: 0.000046
Epoch [93/100], Iter [600/784], Loss: 0.000032
--------------------------------------------------------------------
Epoch [93/100], Test Loss: 0.077765, Overall Accuracy: 98.27%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [94/100], Iter [200/784], Loss: 0.000073
Epoch [94/100], Iter [400/784], Loss: 0.000040
Epoch [94/100], Iter [600/784], Loss: 0.000031
--------------------------------------------------------------------
Epoch [94/100], Test Loss: 0.076694, Overall Accuracy: 98.29%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [95/100], Iter [200/784], Loss: 0.000039
Epoch [95/100], Iter [400/784], Loss: 0.000054
Epoch [95/100], Iter [600/784], Loss: 0.000054
--------------------------------------------------------------------
Epoch [95/100], Test Loss: 0.076109, Overall Accuracy: 98.32%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [96/100], Iter [200/784], Loss: 0.000031
Epoch [96/100], Iter [400/784], Loss: 0.000044
Epoch [96/100], Iter [600/784], Loss: 0.000030
--------------------------------------------------------------------
Epoch [96/100], Test Loss: 0.077241, Overall Accuracy: 98.29%
Highest accuracy: 98.35% achieved at epoch 71
--------------------------------------------------------------------
Epoch [97/100], Iter [200/784], Loss: 0.000040
Epoch [97/100], Iter [400/784], Loss: 0.000027
Epoch [97/100], Iter [600/784], Loss: 0.000057
--------------------------------------------------------------------
Epoch [97/100], Test Loss: 0.075753, Overall Accuracy: 98.35%
Highest accuracy: 98.35% achieved at epoch 97
--------------------------------------------------------------------
Epoch [98/100], Iter [200/784], Loss: 0.000060
Epoch [98/100], Iter [400/784], Loss: 0.000043
Epoch [98/100], Iter [600/784], Loss: 0.000042
--------------------------------------------------------------------
Epoch [98/100], Test Loss: 0.074807, Overall Accuracy: 98.33%
Highest accuracy: 98.35% achieved at epoch 97
--------------------------------------------------------------------
Epoch [99/100], Iter [200/784], Loss: 0.000028
Epoch [99/100], Iter [400/784], Loss: 0.000052
Epoch [99/100], Iter [600/784], Loss: 0.000058
--------------------------------------------------------------------
Epoch [99/100], Test Loss: 0.076207, Overall Accuracy: 98.32%
Highest accuracy: 98.35% achieved at epoch 97
--------------------------------------------------------------------
Epoch [100/100], Iter [200/784], Loss: 0.000036
Epoch [100/100], Iter [400/784], Loss: 0.000049
Epoch [100/100], Iter [600/784], Loss: 0.000033
--------------------------------------------------------------------
Epoch [100/100], Test Loss: 0.077121, Overall Accuracy: 98.27%
Highest accuracy: 98.35% achieved at epoch 97
--------------------------------------------------------------------
Final Evaluation of Locality-iN-Locality Model
Per-Class Accuracy:
Class 0 (0000): 100.00% (60/60)
Class 1 (0001): 100.00% (720/720)
Class 2 (0002): 99.73% (748/750)
Class 3 (0003): 97.11% (437/450)
Class 4 (0004): 99.09% (654/660)
Class 5 (0005): 99.37% (626/630)
Class 6 (0006): 99.33% (149/150)
Class 7 (0007): 99.78% (449/450)
Class 8 (0008): 99.11% (446/450)
Class 9 (0009): 100.00% (480/480)
Class 10 (0010): 99.70% (658/660)
Class 11 (0011): 96.43% (405/420)
Class 12 (0012): 96.23% (664/690)
Class 13 (0013): 99.72% (718/720)
Class 14 (0014): 100.00% (270/270)
Class 15 (0015): 100.00% (210/210)
Class 16 (0016): 100.00% (150/150)
Class 17 (0017): 94.17% (339/360)
Class 18 (0018): 93.85% (366/390)
Class 19 (0019): 100.00% (60/60)
Class 20 (0020): 100.00% (90/90)
Class 21 (0021): 87.78% (79/90)
Class 22 (0022): 93.33% (112/120)
Class 23 (0023): 100.00% (150/150)
Class 24 (0024): 98.89% (89/90)
Class 25 (0025): 99.17% (476/480)
Class 26 (0026): 100.00% (180/180)
Class 27 (0027): 50.00% (30/60)
Class 28 (0028): 99.33% (149/150)
Class 29 (0029): 100.00% (90/90)
Class 30 (0030): 95.33% (143/150)
Class 31 (0031): 98.89% (267/270)
Class 32 (0032): 100.00% (60/60)
Class 33 (0033): 99.52% (209/210)
Class 34 (0034): 100.00% (120/120)
Class 35 (0035): 99.74% (389/390)
Class 36 (0036): 99.17% (119/120)
Class 37 (0037): 100.00% (60/60)
Class 38 (0038): 98.84% (682/690)
Class 39 (0039): 80.00% (72/90)
Class 40 (0040): 96.67% (87/90)
Class 41 (0041): 98.33% (59/60)
Class 42 (0042): 100.00% (90/90)
--------------------------------------------------------------------
Epoch [100/100], Test Loss: 0.077121, Overall Accuracy: 98.27%
Highest accuracy: 98.35% achieved at epoch 97
--------------------------------------------------------------------
Warning: module Unfold is treated as a zero-op.
Warning: module PixelEmbed is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module Attention is treated as a zero-op.
Warning: module Identity is treated as a zero-op.
Warning: module Mlp is treated as a zero-op.
Warning: module MambaVisionMixer is treated as a zero-op.
Warning: module h_sigmoid is treated as a zero-op.
Warning: module h_swish is treated as a zero-op.
Warning: module SELayer is treated as a zero-op.
Warning: module LocalityFeedForward is treated as a zero-op.
Warning: module CrossAttention is treated as a zero-op.
Warning: module Block is treated as a zero-op.
Warning: module LocalViT_TNT is treated as a zero-op.
LocalViT_TNT(
  8.55 M, 99.104% Params, 1.71 GMac, 99.815% MACs, 
  (pixel_embed): PixelEmbed(
    1.78 k, 0.021% Params, 1.39 MMac, 0.081% MACs, 
    (proj): Conv2d(1.78 k, 0.021% Params, 1.39 MMac, 0.081% MACs, 3, 12, kernel_size=(7, 7), stride=(8, 8), padding=(3, 3))
    (unfold): Unfold(0, 0.000% Params, 0.0 Mac, 0.000% MACs, kernel_size=2, dilation=1, padding=0, stride=2)
  )
  (norm1_proj): LayerNorm(96, 0.001% Params, 9.41 KMac, 0.001% MACs, (48,), eps=1e-05, elementwise_affine=True)
  (proj): Linear(9.41 k, 0.109% Params, 1.84 MMac, 0.108% MACs, in_features=48, out_features=192, bias=True)
  (norm2_proj): LayerNorm(384, 0.004% Params, 37.63 KMac, 0.002% MACs, (192,), eps=1e-05, elementwise_affine=True)
  (pos_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)
  (blocks): ModuleList(
    (0-11): 12 x Block(
      710.56 k, 8.239% Params, 142.17 MMac, 8.302% MACs, 
      (norm_in): LayerNorm(24, 0.000% Params, 9.41 KMac, 0.001% MACs, (12,), eps=1e-05, elementwise_affine=True)
      (attn_in): Attention(
        588, 0.007% Params, 460.99 KMac, 0.027% MACs, 
        (qk): Linear(288, 0.003% Params, 225.79 KMac, 0.013% MACs, in_features=12, out_features=24, bias=False)
        (v): Linear(144, 0.002% Params, 112.9 KMac, 0.007% MACs, in_features=12, out_features=12, bias=False)
        (attn_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=True)
        (proj): Linear(156, 0.002% Params, 122.3 KMac, 0.007% MACs, in_features=12, out_features=12, bias=True)
        (proj_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=True)
      )
      (norm_mlp_in): LayerNorm(24, 0.000% Params, 9.41 KMac, 0.001% MACs, (12,), eps=1e-05, elementwise_affine=True)
      (mlp_in): Mlp(
        1.21 k, 0.014% Params, 987.84 KMac, 0.058% MACs, 
        (fc1): Linear(624, 0.007% Params, 489.22 KMac, 0.029% MACs, in_features=12, out_features=48, bias=True)
        (act): GELU(0, 0.000% Params, 37.63 KMac, 0.002% MACs, approximate='none')
        (drop1): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)
        (norm): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
        (fc2): Linear(588, 0.007% Params, 460.99 KMac, 0.027% MACs, in_features=48, out_features=12, bias=True)
        (drop2): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)
      )
      (norm1_proj): LayerNorm(24, 0.000% Params, 9.41 KMac, 0.001% MACs, (12,), eps=1e-05, elementwise_affine=True)
      (proj): Linear(9.41 k, 0.109% Params, 1.84 MMac, 0.108% MACs, in_features=48, out_features=192, bias=True)
      (norm_mamba): LayerNorm(384, 0.004% Params, 37.82 KMac, 0.002% MACs, (192,), eps=1e-05, elementwise_affine=True)
      (mamba_mixer): MambaVisionMixer(
        159.94 k, 1.854% Params, 31.2 MMac, 1.822% MACs, 
        (in_proj): Linear(73.73 k, 0.855% Params, 14.52 MMac, 0.848% MACs, in_features=192, out_features=384, bias=False)
        (x_proj): Linear(8.45 k, 0.098% Params, 1.66 MMac, 0.097% MACs, in_features=192, out_features=44, bias=False)
        (dt_proj): Linear(2.5 k, 0.029% Params, 491.71 KMac, 0.029% MACs, in_features=12, out_features=192, bias=True)
        (out_proj): Linear(73.73 k, 0.855% Params, 14.52 MMac, 0.848% MACs, in_features=384, out_features=192, bias=False)
        (conv1d_x): Conv1d(768, 0.009% Params, 0.0 Mac, 0.000% MACs, 192, 192, kernel_size=(4,), stride=(1,), groups=192, bias=False)
        (conv1d_z): Conv1d(768, 0.009% Params, 0.0 Mac, 0.000% MACs, 192, 192, kernel_size=(4,), stride=(1,), groups=192, bias=False)
      )
      (norm_out): LayerNorm(384, 0.004% Params, 37.82 KMac, 0.002% MACs, (192,), eps=1e-05, elementwise_affine=True)
      (attn_out): Attention(
        147.65 k, 1.712% Params, 29.09 MMac, 1.698% MACs, 
        (qk): Linear(73.73 k, 0.855% Params, 14.52 MMac, 0.848% MACs, in_features=192, out_features=384, bias=False)
        (v): Linear(36.86 k, 0.427% Params, 7.26 MMac, 0.424% MACs, in_features=192, out_features=192, bias=False)
        (attn_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=True)
        (proj): Linear(37.06 k, 0.430% Params, 7.3 MMac, 0.426% MACs, in_features=192, out_features=192, bias=True)
        (proj_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=True)
      )
      (norm_conv): LayerNorm(384, 0.004% Params, 37.63 KMac, 0.002% MACs, (192,), eps=1e-05, elementwise_affine=True)
      (conv): LocalityFeedForward(
        312.2 k, 3.620% Params, 60.29 MMac, 3.521% MACs, 
        (conv): Sequential(
          312.2 k, 3.620% Params, 60.29 MMac, 3.521% MACs, 
          (0): Conv2d(147.46 k, 1.710% Params, 28.9 MMac, 1.688% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1.54 k, 0.018% Params, 301.06 KMac, 0.018% MACs, 768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): h_swish(
            0, 0.000% Params, 150.53 KMac, 0.009% MACs, 
            (sigmoid): h_sigmoid(
              0, 0.000% Params, 150.53 KMac, 0.009% MACs, 
              (relu): ReLU6(0, 0.000% Params, 150.53 KMac, 0.009% MACs, inplace=True)
            )
          )
          (3): Conv2d(6.91 k, 0.080% Params, 1.35 MMac, 0.079% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
          (4): BatchNorm2d(1.54 k, 0.018% Params, 301.06 KMac, 0.018% MACs, 768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): h_swish(
            0, 0.000% Params, 150.53 KMac, 0.009% MACs, 
            (sigmoid): h_sigmoid(
              0, 0.000% Params, 150.53 KMac, 0.009% MACs, 
              (relu): ReLU6(0, 0.000% Params, 150.53 KMac, 0.009% MACs, inplace=True)
            )
          )
          (6): SELayer(
            6.92 k, 0.080% Params, 158.22 KMac, 0.009% MACs, 
            (avg_pool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.009% MACs, output_size=1)
            (fc): Sequential(
              6.92 k, 0.080% Params, 7.69 KMac, 0.000% MACs, 
              (0): Linear(3.08 k, 0.036% Params, 3.08 KMac, 0.000% MACs, in_features=768, out_features=4, bias=True)
              (1): ReLU(0, 0.000% Params, 4.0 Mac, 0.000% MACs, inplace=True)
              (2): Linear(3.84 k, 0.045% Params, 3.84 KMac, 0.000% MACs, in_features=4, out_features=768, bias=True)
              (3): h_sigmoid(
                0, 0.000% Params, 768.0 Mac, 0.000% MACs, 
                (relu): ReLU6(0, 0.000% Params, 768.0 Mac, 0.000% MACs, inplace=True)
              )
            )
          )
          (7): Conv2d(147.46 k, 1.710% Params, 28.9 MMac, 1.688% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(384, 0.004% Params, 75.26 KMac, 0.004% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (drop_path): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
      (cross_attn): CrossAttention(
        78.35 k, 0.908% Params, 18.15 MMac, 1.060% MACs, 
        (to_q): Linear(2.3 k, 0.027% Params, 1.81 MMac, 0.105% MACs, in_features=12, out_features=192, bias=False)
        (to_k): Linear(36.86 k, 0.427% Params, 7.26 MMac, 0.424% MACs, in_features=192, out_features=192, bias=False)
        (to_v): Linear(36.86 k, 0.427% Params, 7.26 MMac, 0.424% MACs, in_features=192, out_features=192, bias=False)
        (to_out): Sequential(
          2.32 k, 0.027% Params, 1.82 MMac, 0.106% MACs, 
          (0): Linear(2.32 k, 0.027% Params, 1.82 MMac, 0.106% MACs, in_features=192, out_features=12, bias=True)
          (1): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)
        )
      )
    )
  )
  (norm): LayerNorm(384, 0.004% Params, 37.82 KMac, 0.002% MACs, (192,), eps=1e-05, elementwise_affine=True)
  (head): Linear(8.3 k, 0.096% Params, 8.3 KMac, 0.000% MACs, in_features=192, out_features=43, bias=True)
)
Computational complexity:       1.71 GMac
Number of parameters:           8.62 M  

Process finished with exit code 0





/home/ai1/anaconda3/envs/thai/bin/python /home/ai1/ThaiLQ/Locality-iN-Locality/train_LiL.py 
PyTorch 2.6.0+cu124
Torchvision 0.21.0+cu124
Torchattacks 3.5.1
Numpy 2.2.3
------------------------------------------------
Epoch [1/100], Iter [200/784], Loss: 3.012272
Epoch [1/100], Iter [400/784], Loss: 1.965091
Epoch [1/100], Iter [600/784], Loss: 1.493608
--------------------------------------------------------------------
Epoch [1/100], Test Loss: 1.095197, Overall Accuracy: 66.56%
Highest accuracy: 66.56% achieved at epoch 1
--------------------------------------------------------------------
Epoch [2/100], Iter [200/784], Loss: 0.228793
Epoch [2/100], Iter [400/784], Loss: 0.369262
Epoch [2/100], Iter [600/784], Loss: 0.049390
--------------------------------------------------------------------
Epoch [2/100], Test Loss: 0.199323, Overall Accuracy: 94.43%
Highest accuracy: 94.43% achieved at epoch 2
--------------------------------------------------------------------
Epoch [3/100], Iter [200/784], Loss: 0.091859
Epoch [3/100], Iter [400/784], Loss: 0.028836
Epoch [3/100], Iter [600/784], Loss: 0.311463
--------------------------------------------------------------------
Epoch [3/100], Test Loss: 0.095688, Overall Accuracy: 97.27%
Highest accuracy: 97.27% achieved at epoch 3
--------------------------------------------------------------------
Epoch [4/100], Iter [200/784], Loss: 0.041708
Epoch [4/100], Iter [400/784], Loss: 1.317076
Epoch [4/100], Iter [600/784], Loss: 0.008628
--------------------------------------------------------------------
Epoch [4/100], Test Loss: 0.128263, Overall Accuracy: 96.71%
Highest accuracy: 97.27% achieved at epoch 3
--------------------------------------------------------------------
Epoch [5/100], Iter [200/784], Loss: 0.027758
Epoch [5/100], Iter [400/784], Loss: 0.008721
Epoch [5/100], Iter [600/784], Loss: 0.018581
--------------------------------------------------------------------
Epoch [5/100], Test Loss: 0.131335, Overall Accuracy: 96.54%
Highest accuracy: 97.27% achieved at epoch 3
--------------------------------------------------------------------
Epoch [6/100], Iter [200/784], Loss: 0.036436
Epoch [6/100], Iter [400/784], Loss: 0.002228
Epoch [6/100], Iter [600/784], Loss: 0.029476
--------------------------------------------------------------------
Epoch [6/100], Test Loss: 0.155197, Overall Accuracy: 96.15%
Highest accuracy: 97.27% achieved at epoch 3
--------------------------------------------------------------------
Epoch [7/100], Iter [200/784], Loss: 0.002284
Epoch [7/100], Iter [400/784], Loss: 0.016111
Epoch [7/100], Iter [600/784], Loss: 0.002382
--------------------------------------------------------------------
Epoch [7/100], Test Loss: 0.079548, Overall Accuracy: 97.66%
Highest accuracy: 97.66% achieved at epoch 7
--------------------------------------------------------------------
Epoch [8/100], Iter [200/784], Loss: 0.002779
Epoch [8/100], Iter [400/784], Loss: 0.001720
Epoch [8/100], Iter [600/784], Loss: 0.190105
--------------------------------------------------------------------
Epoch [8/100], Test Loss: 0.098359, Overall Accuracy: 97.53%
Highest accuracy: 97.66% achieved at epoch 7
--------------------------------------------------------------------
Epoch [9/100], Iter [200/784], Loss: 0.001945
Epoch [9/100], Iter [400/784], Loss: 0.100505
Epoch [9/100], Iter [600/784], Loss: 0.001932
--------------------------------------------------------------------
Epoch [9/100], Test Loss: 0.063420, Overall Accuracy: 97.97%
Highest accuracy: 97.97% achieved at epoch 9
--------------------------------------------------------------------
Epoch [10/100], Iter [200/784], Loss: 0.003781
Epoch [10/100], Iter [400/784], Loss: 0.005985
Epoch [10/100], Iter [600/784], Loss: 0.004387
--------------------------------------------------------------------
Epoch [10/100], Test Loss: 0.104377, Overall Accuracy: 97.13%
Highest accuracy: 97.97% achieved at epoch 9
--------------------------------------------------------------------
Epoch [11/100], Iter [200/784], Loss: 0.004016
Epoch [11/100], Iter [400/784], Loss: 0.025247
Epoch [11/100], Iter [600/784], Loss: 0.039245
--------------------------------------------------------------------
Epoch [11/100], Test Loss: 0.081812, Overall Accuracy: 97.69%
Highest accuracy: 97.97% achieved at epoch 9
--------------------------------------------------------------------
Epoch [12/100], Iter [200/784], Loss: 0.000692
Epoch [12/100], Iter [400/784], Loss: 0.052384
Epoch [12/100], Iter [600/784], Loss: 0.079013
--------------------------------------------------------------------
Epoch [12/100], Test Loss: 0.089541, Overall Accuracy: 97.39%
Highest accuracy: 97.97% achieved at epoch 9
--------------------------------------------------------------------
Epoch [13/100], Iter [200/784], Loss: 0.324657
Epoch [13/100], Iter [400/784], Loss: 0.123615
Epoch [13/100], Iter [600/784], Loss: 0.017810
--------------------------------------------------------------------
Epoch [13/100], Test Loss: 0.087157, Overall Accuracy: 97.65%
Highest accuracy: 97.97% achieved at epoch 9
--------------------------------------------------------------------
Epoch [14/100], Iter [200/784], Loss: 0.001158
Epoch [14/100], Iter [400/784], Loss: 0.002553
Epoch [14/100], Iter [600/784], Loss: 0.002442
--------------------------------------------------------------------
Epoch [14/100], Test Loss: 0.078094, Overall Accuracy: 97.81%
Highest accuracy: 97.97% achieved at epoch 9
--------------------------------------------------------------------
Epoch [15/100], Iter [200/784], Loss: 0.028812
Epoch [15/100], Iter [400/784], Loss: 0.010967
Epoch [15/100], Iter [600/784], Loss: 0.009435
--------------------------------------------------------------------
Epoch [15/100], Test Loss: 0.113506, Overall Accuracy: 96.99%
Highest accuracy: 97.97% achieved at epoch 9
--------------------------------------------------------------------
Epoch [16/100], Iter [200/784], Loss: 0.002529
Epoch [16/100], Iter [400/784], Loss: 0.001800
Epoch [16/100], Iter [600/784], Loss: 0.000757
--------------------------------------------------------------------
Epoch [16/100], Test Loss: 0.092090, Overall Accuracy: 97.60%
Highest accuracy: 97.97% achieved at epoch 9
--------------------------------------------------------------------
Epoch [17/100], Iter [200/784], Loss: 0.042311
Epoch [17/100], Iter [400/784], Loss: 0.000664
Epoch [17/100], Iter [600/784], Loss: 0.000517
--------------------------------------------------------------------
Epoch [17/100], Test Loss: 0.085037, Overall Accuracy: 97.45%
Highest accuracy: 97.97% achieved at epoch 9
--------------------------------------------------------------------
Epoch [18/100], Iter [200/784], Loss: 0.001463
Epoch [18/100], Iter [400/784], Loss: 0.012509
Epoch [18/100], Iter [600/784], Loss: 0.000367
--------------------------------------------------------------------
Epoch [18/100], Test Loss: 0.066766, Overall Accuracy: 98.19%
Highest accuracy: 98.19% achieved at epoch 18
--------------------------------------------------------------------
Epoch [19/100], Iter [200/784], Loss: 0.001341
Epoch [19/100], Iter [400/784], Loss: 0.000818
Epoch [19/100], Iter [600/784], Loss: 0.000859
--------------------------------------------------------------------
Epoch [19/100], Test Loss: 0.065640, Overall Accuracy: 97.97%
Highest accuracy: 98.19% achieved at epoch 18
--------------------------------------------------------------------
Epoch [20/100], Iter [200/784], Loss: 0.001228
Epoch [20/100], Iter [400/784], Loss: 0.000583
Epoch [20/100], Iter [600/784], Loss: 0.000723
--------------------------------------------------------------------
Epoch [20/100], Test Loss: 0.075887, Overall Accuracy: 97.93%
Highest accuracy: 98.19% achieved at epoch 18
--------------------------------------------------------------------
Epoch [21/100], Iter [200/784], Loss: 0.000728
Epoch [21/100], Iter [400/784], Loss: 0.001039
Epoch [21/100], Iter [600/784], Loss: 0.000380
--------------------------------------------------------------------
Epoch [21/100], Test Loss: 0.074097, Overall Accuracy: 97.93%
Highest accuracy: 98.19% achieved at epoch 18
--------------------------------------------------------------------
Epoch [22/100], Iter [200/784], Loss: 0.000599
Epoch [22/100], Iter [400/784], Loss: 0.000310
Epoch [22/100], Iter [600/784], Loss: 0.001069
--------------------------------------------------------------------
Epoch [22/100], Test Loss: 0.084493, Overall Accuracy: 97.65%
Highest accuracy: 98.19% achieved at epoch 18
--------------------------------------------------------------------
Epoch [23/100], Iter [200/784], Loss: 0.001639
Epoch [23/100], Iter [400/784], Loss: 0.001980
Epoch [23/100], Iter [600/784], Loss: 0.001074
--------------------------------------------------------------------
Epoch [23/100], Test Loss: 0.083919, Overall Accuracy: 97.59%
Highest accuracy: 98.19% achieved at epoch 18
--------------------------------------------------------------------
Epoch [24/100], Iter [200/784], Loss: 0.000499
Epoch [24/100], Iter [400/784], Loss: 0.001209
Epoch [24/100], Iter [600/784], Loss: 0.000906
--------------------------------------------------------------------
Epoch [24/100], Test Loss: 0.068468, Overall Accuracy: 98.04%
Highest accuracy: 98.19% achieved at epoch 18
--------------------------------------------------------------------
Epoch [25/100], Iter [200/784], Loss: 0.001141
Epoch [25/100], Iter [400/784], Loss: 0.000381
Epoch [25/100], Iter [600/784], Loss: 0.000669
--------------------------------------------------------------------
Epoch [25/100], Test Loss: 0.087155, Overall Accuracy: 97.70%
Highest accuracy: 98.19% achieved at epoch 18
--------------------------------------------------------------------
Epoch [26/100], Iter [200/784], Loss: 0.000711
Epoch [26/100], Iter [400/784], Loss: 0.000215
Epoch [26/100], Iter [600/784], Loss: 0.002489
--------------------------------------------------------------------
Epoch [26/100], Test Loss: 0.065642, Overall Accuracy: 98.01%
Highest accuracy: 98.19% achieved at epoch 18
--------------------------------------------------------------------
Epoch [27/100], Iter [200/784], Loss: 0.049454
Epoch [27/100], Iter [400/784], Loss: 0.001638
Epoch [27/100], Iter [600/784], Loss: 0.000380
--------------------------------------------------------------------
Epoch [27/100], Test Loss: 0.056369, Overall Accuracy: 98.40%
Highest accuracy: 98.40% achieved at epoch 27
--------------------------------------------------------------------
Epoch [28/100], Iter [200/784], Loss: 0.001033
Epoch [28/100], Iter [400/784], Loss: 0.000527
Epoch [28/100], Iter [600/784], Loss: 0.001738
--------------------------------------------------------------------
Epoch [28/100], Test Loss: 0.074749, Overall Accuracy: 97.74%
Highest accuracy: 98.40% achieved at epoch 27
--------------------------------------------------------------------
Epoch [29/100], Iter [200/784], Loss: 0.000264
Epoch [29/100], Iter [400/784], Loss: 0.006863
Epoch [29/100], Iter [600/784], Loss: 0.143224
--------------------------------------------------------------------
Epoch [29/100], Test Loss: 0.082498, Overall Accuracy: 97.74%
Highest accuracy: 98.40% achieved at epoch 27
--------------------------------------------------------------------
Epoch [30/100], Iter [200/784], Loss: 0.000255
Epoch [30/100], Iter [400/784], Loss: 0.003197
Epoch [30/100], Iter [600/784], Loss: 0.001520
--------------------------------------------------------------------
Epoch [30/100], Test Loss: 0.083395, Overall Accuracy: 97.71%
Highest accuracy: 98.40% achieved at epoch 27
--------------------------------------------------------------------
Epoch [31/100], Iter [200/784], Loss: 0.000306
Epoch [31/100], Iter [400/784], Loss: 0.025223
Epoch [31/100], Iter [600/784], Loss: 0.000499
--------------------------------------------------------------------
Epoch [31/100], Test Loss: 0.085059, Overall Accuracy: 98.08%
Highest accuracy: 98.40% achieved at epoch 27
--------------------------------------------------------------------
Epoch [32/100], Iter [200/784], Loss: 0.000281
Epoch [32/100], Iter [400/784], Loss: 0.000555
Epoch [32/100], Iter [600/784], Loss: 0.000293
--------------------------------------------------------------------
Epoch [32/100], Test Loss: 0.059930, Overall Accuracy: 98.44%
Highest accuracy: 98.44% achieved at epoch 32
--------------------------------------------------------------------
Epoch [33/100], Iter [200/784], Loss: 0.000338
Epoch [33/100], Iter [400/784], Loss: 0.000316
Epoch [33/100], Iter [600/784], Loss: 0.000293
--------------------------------------------------------------------
Epoch [33/100], Test Loss: 0.055614, Overall Accuracy: 98.48%
Highest accuracy: 98.48% achieved at epoch 33
--------------------------------------------------------------------
Epoch [34/100], Iter [200/784], Loss: 0.007639
Epoch [34/100], Iter [400/784], Loss: 0.000612
Epoch [34/100], Iter [600/784], Loss: 0.000245
--------------------------------------------------------------------
Epoch [34/100], Test Loss: 0.072887, Overall Accuracy: 98.08%
Highest accuracy: 98.48% achieved at epoch 33
--------------------------------------------------------------------
Epoch [35/100], Iter [200/784], Loss: 0.000383
Epoch [35/100], Iter [400/784], Loss: 0.000249
Epoch [35/100], Iter [600/784], Loss: 0.000809
--------------------------------------------------------------------
Epoch [35/100], Test Loss: 0.074207, Overall Accuracy: 97.86%
Highest accuracy: 98.48% achieved at epoch 33
--------------------------------------------------------------------
Epoch [36/100], Iter [200/784], Loss: 0.000253
Epoch [36/100], Iter [400/784], Loss: 0.000410
Epoch [36/100], Iter [600/784], Loss: 0.000253
--------------------------------------------------------------------
Epoch [36/100], Test Loss: 0.057135, Overall Accuracy: 98.43%
Highest accuracy: 98.48% achieved at epoch 33
--------------------------------------------------------------------
Epoch [37/100], Iter [200/784], Loss: 0.000543
Epoch [37/100], Iter [400/784], Loss: 0.057802
Epoch [37/100], Iter [600/784], Loss: 0.000378
--------------------------------------------------------------------
Epoch [37/100], Test Loss: 0.053783, Overall Accuracy: 98.70%
Highest accuracy: 98.70% achieved at epoch 37
--------------------------------------------------------------------
Epoch [38/100], Iter [200/784], Loss: 0.000869
Epoch [38/100], Iter [400/784], Loss: 0.001465
Epoch [38/100], Iter [600/784], Loss: 0.000566
--------------------------------------------------------------------
Epoch [38/100], Test Loss: 0.086414, Overall Accuracy: 98.12%
Highest accuracy: 98.70% achieved at epoch 37
--------------------------------------------------------------------
Epoch [39/100], Iter [200/784], Loss: 0.000332
Epoch [39/100], Iter [400/784], Loss: 0.000390
Epoch [39/100], Iter [600/784], Loss: 0.002374
--------------------------------------------------------------------
Epoch [39/100], Test Loss: 0.075604, Overall Accuracy: 97.90%
Highest accuracy: 98.70% achieved at epoch 37
--------------------------------------------------------------------
Epoch [40/100], Iter [200/784], Loss: 0.002991
Epoch [40/100], Iter [400/784], Loss: 0.000321
Epoch [40/100], Iter [600/784], Loss: 0.000701
--------------------------------------------------------------------
Epoch [40/100], Test Loss: 0.064661, Overall Accuracy: 98.24%
Highest accuracy: 98.70% achieved at epoch 37
--------------------------------------------------------------------
Epoch [41/100], Iter [200/784], Loss: 0.345432
Epoch [41/100], Iter [400/784], Loss: 0.001621
Epoch [41/100], Iter [600/784], Loss: 0.000656
--------------------------------------------------------------------
Epoch [41/100], Test Loss: 0.066906, Overall Accuracy: 98.23%
Highest accuracy: 98.70% achieved at epoch 37
--------------------------------------------------------------------
Epoch [42/100], Iter [200/784], Loss: 0.000168
Epoch [42/100], Iter [400/784], Loss: 0.000452
Epoch [42/100], Iter [600/784], Loss: 0.147287
--------------------------------------------------------------------
Epoch [42/100], Test Loss: 0.055652, Overall Accuracy: 98.35%
Highest accuracy: 98.70% achieved at epoch 37
--------------------------------------------------------------------
Epoch [43/100], Iter [200/784], Loss: 0.003646
Epoch [43/100], Iter [400/784], Loss: 0.000171
Epoch [43/100], Iter [600/784], Loss: 0.000385
--------------------------------------------------------------------
Epoch [43/100], Test Loss: 0.049347, Overall Accuracy: 98.63%
Highest accuracy: 98.70% achieved at epoch 37
--------------------------------------------------------------------
Epoch [44/100], Iter [200/784], Loss: 0.000898
Epoch [44/100], Iter [400/784], Loss: 0.000280
Epoch [44/100], Iter [600/784], Loss: 0.000219
--------------------------------------------------------------------
Epoch [44/100], Test Loss: 0.062952, Overall Accuracy: 98.34%
Highest accuracy: 98.70% achieved at epoch 37
--------------------------------------------------------------------
Epoch [45/100], Iter [200/784], Loss: 0.000136
Epoch [45/100], Iter [400/784], Loss: 0.000258
Epoch [45/100], Iter [600/784], Loss: 0.000394
--------------------------------------------------------------------
Epoch [45/100], Test Loss: 0.067706, Overall Accuracy: 98.38%
Highest accuracy: 98.70% achieved at epoch 37
--------------------------------------------------------------------
Epoch [46/100], Iter [200/784], Loss: 0.000615
Epoch [46/100], Iter [400/784], Loss: 0.000223
Epoch [46/100], Iter [600/784], Loss: 0.000119
--------------------------------------------------------------------
Epoch [46/100], Test Loss: 0.052287, Overall Accuracy: 98.50%
Highest accuracy: 98.70% achieved at epoch 37
--------------------------------------------------------------------
Epoch [47/100], Iter [200/784], Loss: 0.000330
Epoch [47/100], Iter [400/784], Loss: 0.000092
Epoch [47/100], Iter [600/784], Loss: 0.000127
--------------------------------------------------------------------
Epoch [47/100], Test Loss: 0.057968, Overall Accuracy: 98.35%
Highest accuracy: 98.70% achieved at epoch 37
--------------------------------------------------------------------
Epoch [48/100], Iter [200/784], Loss: 0.000125
Epoch [48/100], Iter [400/784], Loss: 0.001712
Epoch [48/100], Iter [600/784], Loss: 0.000087
--------------------------------------------------------------------
Epoch [48/100], Test Loss: 0.063075, Overall Accuracy: 98.23%
Highest accuracy: 98.70% achieved at epoch 37
--------------------------------------------------------------------
Epoch [49/100], Iter [200/784], Loss: 0.000513
Epoch [49/100], Iter [400/784], Loss: 0.000283
Epoch [49/100], Iter [600/784], Loss: 0.000121
--------------------------------------------------------------------
Epoch [49/100], Test Loss: 0.078509, Overall Accuracy: 98.13%
Highest accuracy: 98.70% achieved at epoch 37
--------------------------------------------------------------------
Epoch [50/100], Iter [200/784], Loss: 0.000140
Epoch [50/100], Iter [400/784], Loss: 0.000169
Epoch [50/100], Iter [600/784], Loss: 0.000226
--------------------------------------------------------------------
Epoch [50/100], Test Loss: 0.071109, Overall Accuracy: 98.20%
Highest accuracy: 98.70% achieved at epoch 37
--------------------------------------------------------------------
Epoch [51/100], Iter [200/784], Loss: 0.000092
Epoch [51/100], Iter [400/784], Loss: 0.000192
Epoch [51/100], Iter [600/784], Loss: 0.009015
--------------------------------------------------------------------
Epoch [51/100], Test Loss: 0.067406, Overall Accuracy: 98.00%
Highest accuracy: 98.70% achieved at epoch 37
--------------------------------------------------------------------
Epoch [52/100], Iter [200/784], Loss: 0.000110
Epoch [52/100], Iter [400/784], Loss: 0.000155
Epoch [52/100], Iter [600/784], Loss: 0.000199
--------------------------------------------------------------------
Epoch [52/100], Test Loss: 0.092752, Overall Accuracy: 97.78%
Highest accuracy: 98.70% achieved at epoch 37
--------------------------------------------------------------------
Epoch [53/100], Iter [200/784], Loss: 0.000238
Epoch [53/100], Iter [400/784], Loss: 0.000250
Epoch [53/100], Iter [600/784], Loss: 0.000207
--------------------------------------------------------------------
Epoch [53/100], Test Loss: 0.054883, Overall Accuracy: 98.53%
Highest accuracy: 98.70% achieved at epoch 37
--------------------------------------------------------------------
Epoch [54/100], Iter [200/784], Loss: 0.121588
Epoch [54/100], Iter [400/784], Loss: 0.003483
Epoch [54/100], Iter [600/784], Loss: 0.004319
--------------------------------------------------------------------
Epoch [54/100], Test Loss: 0.058950, Overall Accuracy: 98.53%
Highest accuracy: 98.70% achieved at epoch 37
--------------------------------------------------------------------
Epoch [55/100], Iter [200/784], Loss: 0.000088
Epoch [55/100], Iter [400/784], Loss: 0.000202
Epoch [55/100], Iter [600/784], Loss: 0.000222
--------------------------------------------------------------------
Epoch [55/100], Test Loss: 0.073794, Overall Accuracy: 98.36%
Highest accuracy: 98.70% achieved at epoch 37
--------------------------------------------------------------------
Epoch [56/100], Iter [200/784], Loss: 0.000412
Epoch [56/100], Iter [400/784], Loss: 0.021443
Epoch [56/100], Iter [600/784], Loss: 0.216087
--------------------------------------------------------------------
Epoch [56/100], Test Loss: 0.055921, Overall Accuracy: 98.57%
Highest accuracy: 98.70% achieved at epoch 37
--------------------------------------------------------------------
Epoch [57/100], Iter [200/784], Loss: 0.000225
Epoch [57/100], Iter [400/784], Loss: 0.000112
Epoch [57/100], Iter [600/784], Loss: 0.000067
--------------------------------------------------------------------
Epoch [57/100], Test Loss: 0.071013, Overall Accuracy: 98.42%
Highest accuracy: 98.70% achieved at epoch 37
--------------------------------------------------------------------
Epoch [58/100], Iter [200/784], Loss: 0.000575
Epoch [58/100], Iter [400/784], Loss: 0.000220
Epoch [58/100], Iter [600/784], Loss: 0.000101
--------------------------------------------------------------------
Epoch [58/100], Test Loss: 0.065211, Overall Accuracy: 98.42%
Highest accuracy: 98.70% achieved at epoch 37
--------------------------------------------------------------------
Epoch [59/100], Iter [200/784], Loss: 0.000168
Epoch [59/100], Iter [400/784], Loss: 0.000186
Epoch [59/100], Iter [600/784], Loss: 0.000112
--------------------------------------------------------------------
Epoch [59/100], Test Loss: 0.047274, Overall Accuracy: 98.71%
Highest accuracy: 98.71% achieved at epoch 59
--------------------------------------------------------------------
Epoch [60/100], Iter [200/784], Loss: 0.000213
Epoch [60/100], Iter [400/784], Loss: 0.000931
Epoch [60/100], Iter [600/784], Loss: 0.000155
--------------------------------------------------------------------
Epoch [60/100], Test Loss: 0.043680, Overall Accuracy: 98.87%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [61/100], Iter [200/784], Loss: 0.000105
Epoch [61/100], Iter [400/784], Loss: 0.000254
Epoch [61/100], Iter [600/784], Loss: 0.026526
--------------------------------------------------------------------
Epoch [61/100], Test Loss: 0.058816, Overall Accuracy: 98.27%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [62/100], Iter [200/784], Loss: 0.031607
Epoch [62/100], Iter [400/784], Loss: 0.000558
Epoch [62/100], Iter [600/784], Loss: 0.000065
--------------------------------------------------------------------
Epoch [62/100], Test Loss: 0.047824, Overall Accuracy: 98.70%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [63/100], Iter [200/784], Loss: 0.000099
Epoch [63/100], Iter [400/784], Loss: 0.000143
Epoch [63/100], Iter [600/784], Loss: 0.000190
--------------------------------------------------------------------
Epoch [63/100], Test Loss: 0.061479, Overall Accuracy: 98.31%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [64/100], Iter [200/784], Loss: 0.000063
Epoch [64/100], Iter [400/784], Loss: 0.000119
Epoch [64/100], Iter [600/784], Loss: 0.000111
--------------------------------------------------------------------
Epoch [64/100], Test Loss: 0.052799, Overall Accuracy: 98.65%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [65/100], Iter [200/784], Loss: 0.000413
Epoch [65/100], Iter [400/784], Loss: 0.006903
Epoch [65/100], Iter [600/784], Loss: 0.000195
--------------------------------------------------------------------
Epoch [65/100], Test Loss: 0.083750, Overall Accuracy: 97.97%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [66/100], Iter [200/784], Loss: 0.000182
Epoch [66/100], Iter [400/784], Loss: 0.000131
Epoch [66/100], Iter [600/784], Loss: 0.000171
--------------------------------------------------------------------
Epoch [66/100], Test Loss: 0.073515, Overall Accuracy: 98.08%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [67/100], Iter [200/784], Loss: 0.000061
Epoch [67/100], Iter [400/784], Loss: 0.000249
Epoch [67/100], Iter [600/784], Loss: 0.000080
--------------------------------------------------------------------
Epoch [67/100], Test Loss: 0.054124, Overall Accuracy: 98.37%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [68/100], Iter [200/784], Loss: 0.045752
Epoch [68/100], Iter [400/784], Loss: 0.000091
Epoch [68/100], Iter [600/784], Loss: 0.000128
--------------------------------------------------------------------
Epoch [68/100], Test Loss: 0.078217, Overall Accuracy: 98.19%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [69/100], Iter [200/784], Loss: 0.000422
Epoch [69/100], Iter [400/784], Loss: 0.000110
Epoch [69/100], Iter [600/784], Loss: 0.000224
--------------------------------------------------------------------
Epoch [69/100], Test Loss: 0.092019, Overall Accuracy: 97.87%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [70/100], Iter [200/784], Loss: 0.000265
Epoch [70/100], Iter [400/784], Loss: 0.000706
Epoch [70/100], Iter [600/784], Loss: 0.021737
--------------------------------------------------------------------
Epoch [70/100], Test Loss: 0.047553, Overall Accuracy: 98.63%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [71/100], Iter [200/784], Loss: 0.219287
Epoch [71/100], Iter [400/784], Loss: 0.000414
Epoch [71/100], Iter [600/784], Loss: 0.230703
--------------------------------------------------------------------
Epoch [71/100], Test Loss: 0.063519, Overall Accuracy: 98.21%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [72/100], Iter [200/784], Loss: 0.000082
Epoch [72/100], Iter [400/784], Loss: 0.000614
Epoch [72/100], Iter [600/784], Loss: 0.124566
--------------------------------------------------------------------
Epoch [72/100], Test Loss: 0.066427, Overall Accuracy: 98.01%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [73/100], Iter [200/784], Loss: 0.000937
Epoch [73/100], Iter [400/784], Loss: 0.000061
Epoch [73/100], Iter [600/784], Loss: 0.294335
--------------------------------------------------------------------
Epoch [73/100], Test Loss: 0.083802, Overall Accuracy: 97.82%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [74/100], Iter [200/784], Loss: 0.000080
Epoch [74/100], Iter [400/784], Loss: 0.012391
Epoch [74/100], Iter [600/784], Loss: 0.000113
--------------------------------------------------------------------
Epoch [74/100], Test Loss: 0.061461, Overall Accuracy: 98.36%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [75/100], Iter [200/784], Loss: 0.038224
Epoch [75/100], Iter [400/784], Loss: 0.058054
Epoch [75/100], Iter [600/784], Loss: 0.000059
--------------------------------------------------------------------
Epoch [75/100], Test Loss: 0.076563, Overall Accuracy: 98.12%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [76/100], Iter [200/784], Loss: 0.000546
Epoch [76/100], Iter [400/784], Loss: 0.000195
Epoch [76/100], Iter [600/784], Loss: 0.000063
--------------------------------------------------------------------
Epoch [76/100], Test Loss: 0.080002, Overall Accuracy: 98.03%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [77/100], Iter [200/784], Loss: 0.000468
Epoch [77/100], Iter [400/784], Loss: 0.000089
Epoch [77/100], Iter [600/784], Loss: 0.001993
--------------------------------------------------------------------
Epoch [77/100], Test Loss: 0.068379, Overall Accuracy: 98.05%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [78/100], Iter [200/784], Loss: 0.000073
Epoch [78/100], Iter [400/784], Loss: 0.000125
Epoch [78/100], Iter [600/784], Loss: 0.000054
--------------------------------------------------------------------
Epoch [78/100], Test Loss: 0.079309, Overall Accuracy: 98.34%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [79/100], Iter [200/784], Loss: 0.000232
Epoch [79/100], Iter [400/784], Loss: 0.000082
Epoch [79/100], Iter [600/784], Loss: 0.007563
--------------------------------------------------------------------
Epoch [79/100], Test Loss: 0.081250, Overall Accuracy: 98.04%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [80/100], Iter [200/784], Loss: 0.000039
Epoch [80/100], Iter [400/784], Loss: 0.001652
Epoch [80/100], Iter [600/784], Loss: 0.000036
--------------------------------------------------------------------
Epoch [80/100], Test Loss: 0.077377, Overall Accuracy: 98.23%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [81/100], Iter [200/784], Loss: 0.000278
Epoch [81/100], Iter [400/784], Loss: 0.000115
Epoch [81/100], Iter [600/784], Loss: 0.000071
--------------------------------------------------------------------
Epoch [81/100], Test Loss: 0.079370, Overall Accuracy: 97.97%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [82/100], Iter [200/784], Loss: 0.005188
Epoch [82/100], Iter [400/784], Loss: 0.000245
Epoch [82/100], Iter [600/784], Loss: 0.045612
--------------------------------------------------------------------
Epoch [82/100], Test Loss: 0.056080, Overall Accuracy: 98.49%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [83/100], Iter [200/784], Loss: 0.000034
Epoch [83/100], Iter [400/784], Loss: 0.004213
Epoch [83/100], Iter [600/784], Loss: 0.000126
--------------------------------------------------------------------
Epoch [83/100], Test Loss: 0.072275, Overall Accuracy: 98.37%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [84/100], Iter [200/784], Loss: 0.001991
Epoch [84/100], Iter [400/784], Loss: 0.000068
Epoch [84/100], Iter [600/784], Loss: 0.000131
--------------------------------------------------------------------
Epoch [84/100], Test Loss: 0.056875, Overall Accuracy: 98.72%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [85/100], Iter [200/784], Loss: 0.017207
Epoch [85/100], Iter [400/784], Loss: 0.000048
Epoch [85/100], Iter [600/784], Loss: 0.000035
--------------------------------------------------------------------
Epoch [85/100], Test Loss: 0.054710, Overall Accuracy: 98.48%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [86/100], Iter [200/784], Loss: 0.000103
Epoch [86/100], Iter [400/784], Loss: 0.000048
Epoch [86/100], Iter [600/784], Loss: 0.000074
--------------------------------------------------------------------
Epoch [86/100], Test Loss: 0.057069, Overall Accuracy: 98.42%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [87/100], Iter [200/784], Loss: 0.000039
Epoch [87/100], Iter [400/784], Loss: 0.000160
Epoch [87/100], Iter [600/784], Loss: 0.000045
--------------------------------------------------------------------
Epoch [87/100], Test Loss: 0.052523, Overall Accuracy: 98.57%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [88/100], Iter [200/784], Loss: 0.000301
Epoch [88/100], Iter [400/784], Loss: 0.004494
Epoch [88/100], Iter [600/784], Loss: 0.000126
--------------------------------------------------------------------
Epoch [88/100], Test Loss: 0.045650, Overall Accuracy: 98.73%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [89/100], Iter [200/784], Loss: 0.000107
Epoch [89/100], Iter [400/784], Loss: 0.000093
Epoch [89/100], Iter [600/784], Loss: 0.002090
--------------------------------------------------------------------
Epoch [89/100], Test Loss: 0.069206, Overall Accuracy: 98.20%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [90/100], Iter [200/784], Loss: 0.000049
Epoch [90/100], Iter [400/784], Loss: 0.000133
Epoch [90/100], Iter [600/784], Loss: 0.002942
--------------------------------------------------------------------
Epoch [90/100], Test Loss: 0.052936, Overall Accuracy: 98.48%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [91/100], Iter [200/784], Loss: 0.000087
Epoch [91/100], Iter [400/784], Loss: 0.050942
Epoch [91/100], Iter [600/784], Loss: 0.000032
--------------------------------------------------------------------
Epoch [91/100], Test Loss: 0.059784, Overall Accuracy: 98.54%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [92/100], Iter [200/784], Loss: 0.007142
Epoch [92/100], Iter [400/784], Loss: 0.010095
Epoch [92/100], Iter [600/784], Loss: 0.000060
--------------------------------------------------------------------
Epoch [92/100], Test Loss: 0.080765, Overall Accuracy: 98.16%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [93/100], Iter [200/784], Loss: 0.000053
Epoch [93/100], Iter [400/784], Loss: 0.000145
Epoch [93/100], Iter [600/784], Loss: 0.000079
--------------------------------------------------------------------
Epoch [93/100], Test Loss: 0.076227, Overall Accuracy: 98.10%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [94/100], Iter [200/784], Loss: 0.000138
Epoch [94/100], Iter [400/784], Loss: 0.000109
Epoch [94/100], Iter [600/784], Loss: 0.000079
--------------------------------------------------------------------
Epoch [94/100], Test Loss: 0.083577, Overall Accuracy: 98.20%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [95/100], Iter [200/784], Loss: 0.000086
Epoch [95/100], Iter [400/784], Loss: 0.000079
Epoch [95/100], Iter [600/784], Loss: 0.000069
--------------------------------------------------------------------
Epoch [95/100], Test Loss: 0.077867, Overall Accuracy: 98.13%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [96/100], Iter [200/784], Loss: 0.000030
Epoch [96/100], Iter [400/784], Loss: 0.000708
Epoch [96/100], Iter [600/784], Loss: 0.000066
--------------------------------------------------------------------
Epoch [96/100], Test Loss: 0.073861, Overall Accuracy: 98.06%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [97/100], Iter [200/784], Loss: 0.000428
Epoch [97/100], Iter [400/784], Loss: 0.000070
Epoch [97/100], Iter [600/784], Loss: 0.000060
--------------------------------------------------------------------
Epoch [97/100], Test Loss: 0.069225, Overall Accuracy: 98.17%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [98/100], Iter [200/784], Loss: 0.000084
Epoch [98/100], Iter [400/784], Loss: 0.000047
Epoch [98/100], Iter [600/784], Loss: 0.000047
--------------------------------------------------------------------
Epoch [98/100], Test Loss: 0.066715, Overall Accuracy: 98.12%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [99/100], Iter [200/784], Loss: 0.000121
Epoch [99/100], Iter [400/784], Loss: 0.000048
Epoch [99/100], Iter [600/784], Loss: 0.000030
--------------------------------------------------------------------
Epoch [99/100], Test Loss: 0.085286, Overall Accuracy: 98.08%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Epoch [100/100], Iter [200/784], Loss: 0.000045
Epoch [100/100], Iter [400/784], Loss: 0.000077
Epoch [100/100], Iter [600/784], Loss: 0.000061
--------------------------------------------------------------------
Epoch [100/100], Test Loss: 0.088886, Overall Accuracy: 97.61%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
After applying MoEx
Final Evaluation of LNL-MoEx Model
Per-Class Accuracy:
Class 0 (0000): 100.00% (60/60)
Class 1 (0001): 100.00% (720/720)
Class 2 (0002): 100.00% (750/750)
Class 3 (0003): 95.33% (429/450)
Class 4 (0004): 99.70% (658/660)
Class 5 (0005): 94.92% (598/630)
Class 6 (0006): 99.33% (149/150)
Class 7 (0007): 99.56% (448/450)
Class 8 (0008): 92.89% (418/450)
Class 9 (0009): 100.00% (480/480)
Class 10 (0010): 99.55% (657/660)
Class 11 (0011): 100.00% (420/420)
Class 12 (0012): 98.41% (679/690)
Class 13 (0013): 99.72% (718/720)
Class 14 (0014): 100.00% (270/270)
Class 15 (0015): 86.19% (181/210)
Class 16 (0016): 100.00% (150/150)
Class 17 (0017): 93.06% (335/360)
Class 18 (0018): 92.82% (362/390)
Class 19 (0019): 100.00% (60/60)
Class 20 (0020): 100.00% (90/90)
Class 21 (0021): 72.22% (65/90)
Class 22 (0022): 99.17% (119/120)
Class 23 (0023): 92.67% (139/150)
Class 24 (0024): 100.00% (90/90)
Class 25 (0025): 99.17% (476/480)
Class 26 (0026): 100.00% (180/180)
Class 27 (0027): 100.00% (60/60)
Class 28 (0028): 100.00% (150/150)
Class 29 (0029): 100.00% (90/90)
Class 30 (0030): 94.00% (141/150)
Class 31 (0031): 99.63% (269/270)
Class 32 (0032): 100.00% (60/60)
Class 33 (0033): 100.00% (210/210)
Class 34 (0034): 100.00% (120/120)
Class 35 (0035): 100.00% (390/390)
Class 36 (0036): 100.00% (120/120)
Class 37 (0037): 100.00% (60/60)
Class 38 (0038): 97.97% (676/690)
Class 39 (0039): 88.89% (80/90)
Class 40 (0040): 100.00% (90/90)
Class 41 (0041): 63.33% (38/60)
Class 42 (0042): 81.11% (73/90)
--------------------------------------------------------------------
Epoch [100/100], Test Loss: 0.088886, Overall Accuracy: 97.61%
Highest accuracy: 98.87% achieved at epoch 60
--------------------------------------------------------------------
Warning: module Unfold is treated as a zero-op.
Warning: module PixelEmbed is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module Attention is treated as a zero-op.
Warning: module Identity is treated as a zero-op.
Warning: module Mlp is treated as a zero-op.
Warning: module MambaVisionMixer is treated as a zero-op.
Warning: module h_sigmoid is treated as a zero-op.
Warning: module h_swish is treated as a zero-op.
Warning: module SELayer is treated as a zero-op.
Warning: module LocalityFeedForward is treated as a zero-op.
Warning: module CrossAttention is treated as a zero-op.
Warning: module Block is treated as a zero-op.
Warning: module LocalViT_TNT is treated as a zero-op.
LocalViT_TNT(
  8.55 M, 99.104% Params, 1.71 GMac, 99.815% MACs, 
  (pixel_embed): PixelEmbed(
    1.78 k, 0.021% Params, 1.39 MMac, 0.081% MACs, 
    (proj): Conv2d(1.78 k, 0.021% Params, 1.39 MMac, 0.081% MACs, 3, 12, kernel_size=(7, 7), stride=(8, 8), padding=(3, 3))
    (unfold): Unfold(0, 0.000% Params, 0.0 Mac, 0.000% MACs, kernel_size=2, dilation=1, padding=0, stride=2)
  )
  (norm1_proj): LayerNorm(96, 0.001% Params, 9.41 KMac, 0.001% MACs, (48,), eps=1e-05, elementwise_affine=True)
  (proj): Linear(9.41 k, 0.109% Params, 1.84 MMac, 0.108% MACs, in_features=48, out_features=192, bias=True)
  (norm2_proj): LayerNorm(384, 0.004% Params, 37.63 KMac, 0.002% MACs, (192,), eps=1e-05, elementwise_affine=True)
  (pos_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)
  (blocks): ModuleList(
    (0-11): 12 x Block(
      710.56 k, 8.239% Params, 142.17 MMac, 8.302% MACs, 
      (norm_in): LayerNorm(24, 0.000% Params, 9.41 KMac, 0.001% MACs, (12,), eps=1e-05, elementwise_affine=True)
      (attn_in): Attention(
        588, 0.007% Params, 460.99 KMac, 0.027% MACs, 
        (qk): Linear(288, 0.003% Params, 225.79 KMac, 0.013% MACs, in_features=12, out_features=24, bias=False)
        (v): Linear(144, 0.002% Params, 112.9 KMac, 0.007% MACs, in_features=12, out_features=12, bias=False)
        (attn_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=True)
        (proj): Linear(156, 0.002% Params, 122.3 KMac, 0.007% MACs, in_features=12, out_features=12, bias=True)
        (proj_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=True)
      )
      (norm_mlp_in): LayerNorm(24, 0.000% Params, 9.41 KMac, 0.001% MACs, (12,), eps=1e-05, elementwise_affine=True)
      (mlp_in): Mlp(
        1.21 k, 0.014% Params, 987.84 KMac, 0.058% MACs, 
        (fc1): Linear(624, 0.007% Params, 489.22 KMac, 0.029% MACs, in_features=12, out_features=48, bias=True)
        (act): GELU(0, 0.000% Params, 37.63 KMac, 0.002% MACs, approximate='none')
        (drop1): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)
        (norm): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
        (fc2): Linear(588, 0.007% Params, 460.99 KMac, 0.027% MACs, in_features=48, out_features=12, bias=True)
        (drop2): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)
      )
      (norm1_proj): LayerNorm(24, 0.000% Params, 9.41 KMac, 0.001% MACs, (12,), eps=1e-05, elementwise_affine=True)
      (proj): Linear(9.41 k, 0.109% Params, 1.84 MMac, 0.108% MACs, in_features=48, out_features=192, bias=True)
      (norm_mamba): LayerNorm(384, 0.004% Params, 37.82 KMac, 0.002% MACs, (192,), eps=1e-05, elementwise_affine=True)
      (mamba_mixer): MambaVisionMixer(
        159.94 k, 1.854% Params, 31.2 MMac, 1.822% MACs, 
        (in_proj): Linear(73.73 k, 0.855% Params, 14.52 MMac, 0.848% MACs, in_features=192, out_features=384, bias=False)
        (x_proj): Linear(8.45 k, 0.098% Params, 1.66 MMac, 0.097% MACs, in_features=192, out_features=44, bias=False)
        (dt_proj): Linear(2.5 k, 0.029% Params, 491.71 KMac, 0.029% MACs, in_features=12, out_features=192, bias=True)
        (out_proj): Linear(73.73 k, 0.855% Params, 14.52 MMac, 0.848% MACs, in_features=384, out_features=192, bias=False)
        (conv1d_x): Conv1d(768, 0.009% Params, 0.0 Mac, 0.000% MACs, 192, 192, kernel_size=(4,), stride=(1,), groups=192, bias=False)
        (conv1d_z): Conv1d(768, 0.009% Params, 0.0 Mac, 0.000% MACs, 192, 192, kernel_size=(4,), stride=(1,), groups=192, bias=False)
      )
      (norm_out): LayerNorm(384, 0.004% Params, 37.82 KMac, 0.002% MACs, (192,), eps=1e-05, elementwise_affine=True)
      (attn_out): Attention(
        147.65 k, 1.712% Params, 29.09 MMac, 1.698% MACs, 
        (qk): Linear(73.73 k, 0.855% Params, 14.52 MMac, 0.848% MACs, in_features=192, out_features=384, bias=False)
        (v): Linear(36.86 k, 0.427% Params, 7.26 MMac, 0.424% MACs, in_features=192, out_features=192, bias=False)
        (attn_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=True)
        (proj): Linear(37.06 k, 0.430% Params, 7.3 MMac, 0.426% MACs, in_features=192, out_features=192, bias=True)
        (proj_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=True)
      )
      (norm_conv): LayerNorm(384, 0.004% Params, 37.63 KMac, 0.002% MACs, (192,), eps=1e-05, elementwise_affine=True)
      (conv): LocalityFeedForward(
        312.2 k, 3.620% Params, 60.29 MMac, 3.521% MACs, 
        (conv): Sequential(
          312.2 k, 3.620% Params, 60.29 MMac, 3.521% MACs, 
          (0): Conv2d(147.46 k, 1.710% Params, 28.9 MMac, 1.688% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1.54 k, 0.018% Params, 301.06 KMac, 0.018% MACs, 768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): h_swish(
            0, 0.000% Params, 150.53 KMac, 0.009% MACs, 
            (sigmoid): h_sigmoid(
              0, 0.000% Params, 150.53 KMac, 0.009% MACs, 
              (relu): ReLU6(0, 0.000% Params, 150.53 KMac, 0.009% MACs, inplace=True)
            )
          )
          (3): Conv2d(6.91 k, 0.080% Params, 1.35 MMac, 0.079% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
          (4): BatchNorm2d(1.54 k, 0.018% Params, 301.06 KMac, 0.018% MACs, 768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): h_swish(
            0, 0.000% Params, 150.53 KMac, 0.009% MACs, 
            (sigmoid): h_sigmoid(
              0, 0.000% Params, 150.53 KMac, 0.009% MACs, 
              (relu): ReLU6(0, 0.000% Params, 150.53 KMac, 0.009% MACs, inplace=True)
            )
          )
          (6): SELayer(
            6.92 k, 0.080% Params, 158.22 KMac, 0.009% MACs, 
            (avg_pool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.009% MACs, output_size=1)
            (fc): Sequential(
              6.92 k, 0.080% Params, 7.69 KMac, 0.000% MACs, 
              (0): Linear(3.08 k, 0.036% Params, 3.08 KMac, 0.000% MACs, in_features=768, out_features=4, bias=True)
              (1): ReLU(0, 0.000% Params, 4.0 Mac, 0.000% MACs, inplace=True)
              (2): Linear(3.84 k, 0.045% Params, 3.84 KMac, 0.000% MACs, in_features=4, out_features=768, bias=True)
              (3): h_sigmoid(
                0, 0.000% Params, 768.0 Mac, 0.000% MACs, 
                (relu): ReLU6(0, 0.000% Params, 768.0 Mac, 0.000% MACs, inplace=True)
              )
            )
          )
          (7): Conv2d(147.46 k, 1.710% Params, 28.9 MMac, 1.688% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(384, 0.004% Params, 75.26 KMac, 0.004% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (drop_path): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
      (cross_attn): CrossAttention(
        78.35 k, 0.908% Params, 18.15 MMac, 1.060% MACs, 
        (to_q): Linear(2.3 k, 0.027% Params, 1.81 MMac, 0.105% MACs, in_features=12, out_features=192, bias=False)
        (to_k): Linear(36.86 k, 0.427% Params, 7.26 MMac, 0.424% MACs, in_features=192, out_features=192, bias=False)
        (to_v): Linear(36.86 k, 0.427% Params, 7.26 MMac, 0.424% MACs, in_features=192, out_features=192, bias=False)
        (to_out): Sequential(
          2.32 k, 0.027% Params, 1.82 MMac, 0.106% MACs, 
          (0): Linear(2.32 k, 0.027% Params, 1.82 MMac, 0.106% MACs, in_features=192, out_features=12, bias=True)
          (1): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)
        )
      )
    )
  )
  (norm): LayerNorm(384, 0.004% Params, 37.82 KMac, 0.002% MACs, (192,), eps=1e-05, elementwise_affine=True)
  (head): Linear(8.3 k, 0.096% Params, 8.3 KMac, 0.000% MACs, in_features=192, out_features=43, bias=True)
)
Computational complexity:       1.71 GMac
Number of parameters:           8.62 M  

Process finished with exit code 0
